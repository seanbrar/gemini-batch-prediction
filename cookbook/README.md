# Gemini Batch Processing Cookbook

Problem-first recipes for real-world multimodal analysis

## ğŸš€ Getting Started

Perfect for first-time users

| Recipe | When you need to... | Difficulty | Time |
|--------|----------------------|------------|------|
| `getting-started/analyze-single-paper.py` | Extract key insights from one file | â­ | 5 min |
| `getting-started/batch-process-files.py` | Process multiple documents efficiently | â­â­ | 8 min |
| `getting-started/extract-video-insights.py` | Pull highlights from a video | â­â­ | 8 min |
| `getting-started/token-estimate-preview.py` | Estimate tokens/cost before running | â­â­ | 5â€“8 min |
| `getting-started/structured-json-robust.py` | Get JSON with schema + fallbacks | â­â­ | 8â€“10 min |
| `getting-started/youtube-qa-timestamps.py` | Q&A on YouTube with timestamp links | â­â­ | 8 min |
| `getting-started/conversation-follow-ups.py` | Persisted follow-ups via ConversationEngine | â­â­ | 8â€“10 min |

## ğŸ“š Research Workflows

Academic and educational scenarios

- `research-workflows/literature-synthesis.py` â€” Synthesize findings across many papers
- `research-workflows/comparative-analysis.py` â€” Compare two or more sources sideâ€‘byâ€‘side
- `research-workflows/content-assessment.py` â€” Assess course/lecture materials for learning objectives
- `research-workflows/fact-table-extraction.py` â€” Extract normalized fact rows to JSONL/CSV
- `research-workflows/multi-video-batch.py` â€” Compare/summarize across up to 10 videos
- `research-workflows/system-instructions-with-research-helper.py` â€” Apply system instructions while benchmarking efficiency

## âš™ï¸ Optimization

Performance, scale, and cost efficiency

- `optimization/cache-warming-and-ttl.py` â€” Warm caches with deterministic keys and TTL
- `optimization/chunking-large-docs.py` â€” Chunk very large docs and merge answers
- `optimization/large-scale-batching.py` â€” Fanâ€‘out over many sources with bounded concurrency
- `optimization/multi-format-pipeline.py` â€” Analyze mixed media (PDF, image, video) together
- `optimization/context-caching-explicit.py` â€” Explicit cache create/reuse and token savings
- `optimization/long-transcript-chunking.py` â€” Token-aware transcript chunking + stitching
- `optimization/efficiency-comparison.py` â€” Compare vectorized vs naive for N prompts

## ğŸ­ Production Patterns

Reliability and observability

- `production/monitoring-telemetry.py` â€” Inspect perâ€‘stage timings and metrics
- `production/resume-on-failure.py` â€” Persist state and rerun only failed items
- `production/custom-integrations.py` â€” Attach a custom telemetry reporter
- `production/rate-limits-and-concurrency.py` â€” Tier config + bounded concurrency behavior

## ğŸ§© Templates

- `templates/recipe-template.py` â€” Boilerplate for a new recipe
- `templates/custom-schema-template.py` â€” Start here for schemaâ€‘first extraction

Notes

- Set `GEMINI_API_KEY` and any model/tier env as needed.
- Run `make fetch-cookbook-data` to download small public samples into `cookbook/data/public/`.
- Scripts default to `cookbook/data/public/` (fallback to `examples/test_data` if present).
- Add `--log-cli-level=INFO` to pytest commands to view more logs.
